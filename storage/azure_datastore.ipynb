{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CREATE BLOB STORAGE**\n",
    "\n",
    "[Setting up](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python)\n",
    "\n",
    "[Documentation](https://docs.microsoft.com/en-us/python/api/azure-storage-blob/azure.storage.blob?view=azure-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid, sys\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_str='XXX'\n",
    "container_name ='containerstorage01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Create container and folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "try:\n",
    "    container_client = blob_service_client.create_container(container_name)\n",
    "except:\n",
    "    container_client = blob_service_client.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Upload data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Upload files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    \"\"\"Return all files in the directory\"\"\"\n",
    "    all_files = []\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            all_files.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "    return all_files\n",
    "\n",
    "def upload_all_files_to_container(connect_str, container_name, directory):\n",
    "    \"\"\"Upload all file from the local directory to Azure container.\"\"\"\n",
    "    all_files = absoluteFilePaths(directory)\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            file_path_azure = file_path.replace(os.path.abspath(directory), directory.replace('./', ''))\n",
    "            blobclient = BlobClient.from_connection_string(connect_str, container_name, file_path_azure)\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                blobclient.upload_blob(data)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_all_files_to_container(connect_str, container_name, './data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Upload directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dir(connect_str, container_name, local_source, azure_destination):\n",
    "    \"\"\"\n",
    "    Function which upload directory from the local directory to Container\n",
    "    in Azure Storage if such not exists.\n",
    "    \n",
    "    sample inputs:\n",
    "    connect_str = 'DefaultEndpointsProt...'\n",
    "    container_name = syndicaistorage01\n",
    "    local_source = './data'\n",
    "    local_destination = 'data'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get container or create if not exists\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    try:\n",
    "        container_client = blob_service_client.create_container(container_name)\n",
    "    except:\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        \n",
    "    # list all files in directory\n",
    "    all_files = []\n",
    "    for dirpath,_,filenames in os.walk(local_source):\n",
    "        for f in filenames:\n",
    "            all_files.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "            \n",
    "    # upload files\n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            file_path_azure = '/'.join([azure_destination, file_path[len(os.path.abspath(local_source)) + 1:]])\n",
    "            blobclient = BlobClient.from_connection_string(connect_str, container_name, file_path_azure)\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                blobclient.upload_blob(data)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_dir(connect_str, container_name, './data', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Download directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dir(connect_str, container_name, directory, local_destination):\n",
    "    \"\"\"\n",
    "    Function which download directory from the azure directory in Container \n",
    "    in Azure Storage to local destination.\n",
    "    \n",
    "    sample inputs:\n",
    "    connect_str = 'DefaultEndpointsProt...'\n",
    "    container_name = containerstorage01\n",
    "    directory = 'data'\n",
    "    local_destination = './data'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get container or create if not exists\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    try:\n",
    "        container_client = blob_service_client.create_container(container_name)\n",
    "    except:\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "    \n",
    "    # iterate over all files\n",
    "    for blob in container_client.list_blobs(name_starts_with=directory):\n",
    "        name = blob.name[len(directory) + 1:]\n",
    "        # Check if blob.name is a directory create it locally\n",
    "        if \"/\" in name:\n",
    "            os.makedirs(os.path.join(local_destination, os.path.dirname(name)), exist_ok=True)\n",
    "        \n",
    "        # download file\n",
    "        blobclient = BlobClient.from_connection_string(connect_str, container_name, blob.name)\n",
    "        with open(os.path.join(local_destination, name), \"wb\") as download_file:\n",
    "            download_file.write(blobclient.download_blob().readall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir(connect_str, container_name, 'data', './data2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
